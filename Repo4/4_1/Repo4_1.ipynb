{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8aaed48-8051-40f8-9839-6ddeefaec339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02992b4-2ed5-484c-b65a-87342bbd2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Uncleaned_Cnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e3d06d-9dcd-424d-a1ae-320514b7b07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>College grad challenges Justice Thomas' argume...</td>\n",
       "      <td>2.9K views</td>\n",
       "      <td>19 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>College grad challenges Justice Thomas' argume...</td>\n",
       "      <td>2.9K views</td>\n",
       "      <td>19 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI needs 'a new era of law and regulation,' sa...</td>\n",
       "      <td>10K views</td>\n",
       "      <td>9 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hear why Pence wanted to meet with Zelensky an...</td>\n",
       "      <td>86K views</td>\n",
       "      <td>16 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watch as verdict is read in former Parkland sc...</td>\n",
       "      <td>26K views</td>\n",
       "      <td>21 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>CNN fact-checks Biden's State of the Union speech</td>\n",
       "      <td>135K views</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Russian mercenaries reveal what happened to so...</td>\n",
       "      <td>1.2M views</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Video shows trapped child comfort sibling unde...</td>\n",
       "      <td>123K views</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>'Liar!': Marjorie Taylor Greene interrupts Bid...</td>\n",
       "      <td>1.1M views</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>McCarthy reveals Santos is facing House ethics...</td>\n",
       "      <td>270K views</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title       views  \\\n",
       "0    College grad challenges Justice Thomas' argume...  2.9K views   \n",
       "1    College grad challenges Justice Thomas' argume...  2.9K views   \n",
       "2    AI needs 'a new era of law and regulation,' sa...   10K views   \n",
       "3    Hear why Pence wanted to meet with Zelensky an...   86K views   \n",
       "4    Watch as verdict is read in former Parkland sc...   26K views   \n",
       "..                                                 ...         ...   \n",
       "423  CNN fact-checks Biden's State of the Union speech  135K views   \n",
       "424  Russian mercenaries reveal what happened to so...  1.2M views   \n",
       "425  Video shows trapped child comfort sibling unde...  123K views   \n",
       "426  'Liar!': Marjorie Taylor Greene interrupts Bid...  1.1M views   \n",
       "427  McCarthy reveals Santos is facing House ethics...  270K views   \n",
       "\n",
       "               when  \n",
       "0    19 minutes ago  \n",
       "1    19 minutes ago  \n",
       "2       9 hours ago  \n",
       "3      16 hours ago  \n",
       "4      21 hours ago  \n",
       "..              ...  \n",
       "423    4 months ago  \n",
       "424    4 months ago  \n",
       "425    4 months ago  \n",
       "426    4 months ago  \n",
       "427    4 months ago  \n",
       "\n",
       "[428 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc05666-7dbf-4023-8e8e-48ac211908d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>when</th>\n",
       "      <th>views_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>College grad challenges Justice Thomas' argume...</td>\n",
       "      <td>2.9K</td>\n",
       "      <td>19 minutes ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>College grad challenges Justice Thomas' argume...</td>\n",
       "      <td>2.9K</td>\n",
       "      <td>19 minutes ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI needs 'a new era of law and regulation,' sa...</td>\n",
       "      <td>10K</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hear why Pence wanted to meet with Zelensky an...</td>\n",
       "      <td>86K</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watch as verdict is read in former Parkland sc...</td>\n",
       "      <td>26K</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>CNN fact-checks Biden's State of the Union speech</td>\n",
       "      <td>135K</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Russian mercenaries reveal what happened to so...</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Video shows trapped child comfort sibling unde...</td>\n",
       "      <td>123K</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>'Liar!': Marjorie Taylor Greene interrupts Bid...</td>\n",
       "      <td>1.1M</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>McCarthy reveals Santos is facing House ethics...</td>\n",
       "      <td>270K</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title views            when  \\\n",
       "0    College grad challenges Justice Thomas' argume...  2.9K  19 minutes ago   \n",
       "1    College grad challenges Justice Thomas' argume...  2.9K  19 minutes ago   \n",
       "2    AI needs 'a new era of law and regulation,' sa...   10K     9 hours ago   \n",
       "3    Hear why Pence wanted to meet with Zelensky an...   86K    16 hours ago   \n",
       "4    Watch as verdict is read in former Parkland sc...   26K    21 hours ago   \n",
       "..                                                 ...   ...             ...   \n",
       "423  CNN fact-checks Biden's State of the Union speech  135K    4 months ago   \n",
       "424  Russian mercenaries reveal what happened to so...  1.2M    4 months ago   \n",
       "425  Video shows trapped child comfort sibling unde...  123K    4 months ago   \n",
       "426  'Liar!': Marjorie Taylor Greene interrupts Bid...  1.1M    4 months ago   \n",
       "427  McCarthy reveals Santos is facing House ethics...  270K    4 months ago   \n",
       "\n",
       "    views_text  \n",
       "0        views  \n",
       "1        views  \n",
       "2        views  \n",
       "3        views  \n",
       "4        views  \n",
       "..         ...  \n",
       "423      views  \n",
       "424      views  \n",
       "425      views  \n",
       "426      views  \n",
       "427      views  \n",
       "\n",
       "[428 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting \"views\" column into columns \"views\" and \"views_text\"\n",
    "df[['views','views_text']] = df['views'].str.split(expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cdcee50-c62a-463b-835d-3a68c8482701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Column \"views_txt\"\n",
    "df.drop(\"views_text\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56657c21-25fa-4784-9417-f4c9de261ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates 'title'\n",
    "df.drop_duplicates('title',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eaefa64-16ba-4aca-ac62-766d5509d2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>College grad challenges Justice Thomas' argume...</td>\n",
       "      <td>2.9K</td>\n",
       "      <td>19 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI needs 'a new era of law and regulation,' sa...</td>\n",
       "      <td>10K</td>\n",
       "      <td>9 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hear why Pence wanted to meet with Zelensky an...</td>\n",
       "      <td>86K</td>\n",
       "      <td>16 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Watch as verdict is read in former Parkland sc...</td>\n",
       "      <td>26K</td>\n",
       "      <td>21 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legal analyst identifies part of ruling that l...</td>\n",
       "      <td>86K</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>CNN fact-checks Biden's State of the Union speech</td>\n",
       "      <td>135K</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Russian mercenaries reveal what happened to so...</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Video shows trapped child comfort sibling unde...</td>\n",
       "      <td>123K</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>'Liar!': Marjorie Taylor Greene interrupts Bid...</td>\n",
       "      <td>1.1M</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>McCarthy reveals Santos is facing House ethics...</td>\n",
       "      <td>270K</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title views            when\n",
       "0    College grad challenges Justice Thomas' argume...  2.9K  19 minutes ago\n",
       "1    AI needs 'a new era of law and regulation,' sa...   10K     9 hours ago\n",
       "2    Hear why Pence wanted to meet with Zelensky an...   86K    16 hours ago\n",
       "3    Watch as verdict is read in former Parkland sc...   26K    21 hours ago\n",
       "4    Legal analyst identifies part of ruling that l...   86K       1 day ago\n",
       "..                                                 ...   ...             ...\n",
       "422  CNN fact-checks Biden's State of the Union speech  135K    4 months ago\n",
       "423  Russian mercenaries reveal what happened to so...  1.2M    4 months ago\n",
       "424  Video shows trapped child comfort sibling unde...  123K    4 months ago\n",
       "425  'Liar!': Marjorie Taylor Greene interrupts Bid...  1.1M    4 months ago\n",
       "426  McCarthy reveals Santos is facing House ethics...  270K    4 months ago\n",
       "\n",
       "[427 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resetting Index after removing duplicates\n",
    "x = list(range(0,len(df)))\n",
    "df.index = x\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6858745-8cb8-4ff1-89d6-6aebdef53dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Hear Chinese warning to US plane in midair ove...</td>\n",
       "      <td>5.9 million</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>CNN follows migrants illegally entering Canada...</td>\n",
       "      <td>3.4 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Russia is ‘getting hammered’: Top US general o...</td>\n",
       "      <td>3.1 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Jon Stewart: This is why Trump became popular ...</td>\n",
       "      <td>2.8 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Historian predicts how Russia's war in Ukraine...</td>\n",
       "      <td>2.1 million</td>\n",
       "      <td>4 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>See Marjorie Taylor Greene's reaction when GOP...</td>\n",
       "      <td>1.7 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>A blob twice the width of the US is heading to...</td>\n",
       "      <td>1.7 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Bolton makes prediction on Trump's political c...</td>\n",
       "      <td>1.7 million</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Hear what Xi said to Putin during critical mee...</td>\n",
       "      <td>1.6 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Bill Maher on wokeness and why having an older...</td>\n",
       "      <td>1.5 million</td>\n",
       "      <td>3 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title        views  \\\n",
       "371  Hear Chinese warning to US plane in midair ove...  5.9 million   \n",
       "319  CNN follows migrants illegally entering Canada...  3.4 million   \n",
       "269  Russia is ‘getting hammered’: Top US general o...  3.1 million   \n",
       "278  Jon Stewart: This is why Trump became popular ...  2.8 million   \n",
       "370  Historian predicts how Russia's war in Ukraine...  2.1 million   \n",
       "355  See Marjorie Taylor Greene's reaction when GOP...  1.7 million   \n",
       "312  A blob twice the width of the US is heading to...  1.7 million   \n",
       "55   Bolton makes prediction on Trump's political c...  1.7 million   \n",
       "298  Hear what Xi said to Putin during critical mee...  1.6 million   \n",
       "359  Bill Maher on wokeness and why having an older...  1.5 million   \n",
       "\n",
       "             when  \n",
       "371  4 months ago  \n",
       "319  3 months ago  \n",
       "269  3 months ago  \n",
       "278  3 months ago  \n",
       "370  4 months ago  \n",
       "355  3 months ago  \n",
       "312  3 months ago  \n",
       "55    2 weeks ago  \n",
       "298  3 months ago  \n",
       "359  3 months ago  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import humanize\n",
    "\n",
    "# Convert the 'views' column to numeric values\n",
    "df['views'] = df['views'].str.replace('K', 'e3').str.replace('M', 'e6').astype(float)\n",
    "\n",
    "# Sort the DataFrame based on views in descending order\n",
    "sorted_df = df.sort_values('views', ascending=False)\n",
    "\n",
    "# Get the top 10 titles, views, and when\n",
    "top_10_titles = sorted_df[['title', 'views', 'when']].head(10)\n",
    "\n",
    "# Format the 'views' column using humanize library\n",
    "top_10_titles['views'] = top_10_titles['views'].apply(lambda x: humanize.intword(x))\n",
    "\n",
    "# Display the table using pandas DataFrame\n",
    "top_10_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fdf214-6f45-43c5-8cf6-8e6bd8426f68",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\NHQE1/nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m all_titles \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tokenize the titles into individual words\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_titles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Remove stopwords from the list of words\u001b[39;00m\n\u001b[0;32m      8\u001b[0m stopwords_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\NHQE1/nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\NHQE1\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Combine all the titles into a single string\n",
    "all_titles = ' '.join(df['title'])\n",
    "\n",
    "# Tokenize the titles into individual words\n",
    "words = word_tokenize(all_titles)\n",
    "\n",
    "# Remove stopwords from the list of words\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stopwords_list]\n",
    "\n",
    "# Join the filtered words back into a single string\n",
    "filtered_titles = ' '.join(filtered_words)\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(width=1000, height=600, background_color='black').generate(filtered_titles)\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71e975-f0e9-475f-8cf2-a163d9cca262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
